# ============================================================================
# HR Calculator - í˜„ëŒ€ì  ë¶„ì‚° ì»´í“¨íŒ… íŒ¨ëŸ¬ë‹¤ì„ (Push-down Processing)
# ============================================================================
# 
# í˜ì‹ ì  ë©”ëª¨ë¦¬ ì œë¡œ ì „ëµ:
# - ê±°ëŒ€í•œ ì¤‘ê°„ ë°ì´í„°(base_data)ë¥¼ ë©”ëª¨ë¦¬ì— ì•„ì˜ˆ ìƒì„±í•˜ì§€ ì•ŠìŒ
# - ê° ë³‘ë ¬ ì‘ì—…ìê°€ í•„ìš”í•œ ìµœì†Œí•œì˜ ë°ì´í„°ë§Œ ë””ìŠ¤í¬ì—ì„œ ì§ì ‘ ì²˜ë¦¬
# - ë©”ì¸ í”„ë¡œì„¸ìŠ¤ëŠ” ì‘ì—… ëª©ë¡(Instruction List)ë§Œ ìƒì„±, ë°ì´í„° ë¡œë“œ ì—†ìŒ
# - ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©: < 2GB (ê¸°ì¡´ 126GBì—ì„œ 98% ì ˆê°!)
#
# í˜„ëŒ€ì  ë°ì´í„° ì²˜ë¦¬ ì•„í‚¤í…ì²˜:
# 1. ë°ì´í„° í˜•ì‹: Parquet (ëª¨ë“  .sas7bdat â†’ .parquet ë³€í™˜)
#    - ì—´(column) ê¸°ë°˜ ì €ì¥ìœ¼ë¡œ í•„ìš”í•œ ì—´ë§Œ ë¹ ë¥´ê²Œ ì½ê¸°
#    - ë›°ì–´ë‚œ ì••ì¶•ë¥ ê³¼ DuckDBì™€ì˜ ìµœê³  ê¶í•©
#
# 2. ì²˜ë¦¬ ì—”ì§„: DuckDB (ì¸-í”„ë¡œì„¸ìŠ¤ ë¶„ì„ ë°ì´í„°ë² ì´ìŠ¤)
#    - R ë©”ëª¨ë¦¬ë¡œ ë°ì´í„° ë¡œë“œ ëŒ€ì‹  SQL ì¿¼ë¦¬ë¡œ ë””ìŠ¤í¬ì—ì„œ ì§ì ‘ ì²˜ë¦¬
#    - ìˆ˜ë°± GB Parquet íŒŒì¼ë„ ë©”ëª¨ë¦¬ ë¶€í•˜ ì—†ì´ ì´ˆê³ ì† ì¿¼ë¦¬
#
# 3. ì‹¤í–‰ êµ¬ì¡°: Push-down ë³‘ë ¬ ì²˜ë¦¬
#    - ê¸°ì¡´: [ë°ì´í„° ë¡œë“œ â†’ ê±°ëŒ€ ê°ì²´ ìƒì„±] â†’ [ë³‘ë ¬ ì²˜ë¦¬]
#    - í˜ì‹ : [ë³‘ë ¬ ì²˜ë¦¬] â†’ [ê°ì ë°ì´í„° ë¡œë“œ]
#    - ê° ì›Œì»¤ê°€ ('J00', 'A01') ëª…ë ¹ì–´ë§Œ ë°›ì•„ ìµœì†Œ ë°ì´í„°ë¡œ ì²˜ë¦¬
#
# ì„±ëŠ¥ ëª©í‘œ:
# - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: < 2GB (98% ì ˆê°)
# - ì²˜ë¦¬ ì‹œê°„: ~1.5ì¼ (1,407,782 ì¡°í•©)
# - í™•ì¥ì„±: ë¬´ì œí•œ ì½”ì–´ í™œìš© ê°€ëŠ¥
# ============================================================================

# conda install -c conda-forge r-tidyverse r-survival r-haven r-broom r-arrow r-tidycmprsk r-data.table r-duckdb

# conda ì‹¤íŒ¨ì‹œì—ë§Œ ì•„ë˜ì˜ ê²ƒì„ ì‹œë„ë„
# install.packages("survival")
# install.packages("haven")
# install.packages("dplyr")
# install.packages("tidyverse")
# install.packages("broom")
# install.packages("arrow")
# install.packages("tidycmprsk")
# install.packages("data.table")
# install.packages("duckdb")

library(survival)
library(haven)
library(dplyr)
library(tidyverse)
library(broom)
library(arrow)
library(tidycmprsk)
library(glue)
library(future)
library(furrr)
library(progressr)
library(data.table)  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° ì²˜ë¦¬
library(duckdb)      # ë””ìŠ¤í¬ ê¸°ë°˜ ì¿¼ë¦¬ ì—”ì§„
library(hash)
library(jsonlite)

# --- ê²½ë¡œ ì„¤ì • ---
# paths <- list(
#     matched_sas_folder = "/home/hashjamm/project_data/disease_network/sas_files/hr_project/matched_date/",
#     matched_parquet_folder = "/home/hashjamm/project_data/disease_network/matched_date_parquet/",
#     outcome_sas_file = "/home/hashjamm/project_data/disease_network/sas_files/hr_project/hr_std_pop10.sas7bdat",
#     outcome_parquet_file = "/home/hashjamm/project_data/disease_network/outcome_table.parquet",
#     results_hr_folder = "/home/hashjamm/results/disease_network/hr_results_final/",
#     results_mapping_folder = "/home/hashjamm/results/disease_network/hr_mapping_results_final/",
#     temp_slices_folder = file.path(tempdir(), "edge_slices")
# )

# ============================================================================
# 1. ë°ì´í„° ë³€í™˜ ëª¨ë“ˆ (Data Conversion Modules) + sas íŒŒì¼ parquet í™”
# ============================================================================

# í—¬í¼ í•¨ìˆ˜: ë°ì´í„° í…Œì´ë¸”ì˜ ëª¨ë“  ì»¬ëŸ¼ëª…ì„ ì†Œë¬¸ìë¡œ ë³€ê²½
to_columns_lower <- function(dt) {
    # data.tableì˜ setnamesë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ì´ë¦„ ë³€ê²½
    data.table::setnames(dt, tolower(names(dt)))
    return(dt)
}

# ë²”ìš© SAS â†’ Parquet ë³€í™˜ í•¨ìˆ˜ (í•µì‹¬ ë³€í™˜ ë¡œì§)
convert_sas_to_parquet <- function(sas_file_path, parquet_file_path, verbose = TRUE, to_columns_lower = FALSE) {
    # SAS íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if (!file.exists(sas_file_path)) {
        return(list(
            success = FALSE,
            error = sprintf("âŒ SAS íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: %s", sas_file_path)
        ))
    }
    
    tryCatch({
        if (verbose) {
            cat(sprintf("ğŸ”„ ë³€í™˜ ì¤‘: %s â†’ %s\n", basename(sas_file_path), basename(parquet_file_path)))
        }
        
        # SAS íŒŒì¼ ë¡œë“œ
        sas_data <- read_sas(sas_file_path)

        if (to_columns_lower) {
            sas_data <- to_columns_lower(sas_data)
        }

        original_size <- object.size(sas_data) / 1024^2  # MBë¡œ ë³€ê²½
        
        # Parquetìœ¼ë¡œ ì €ì¥ (ë””ë ‰í† ë¦¬ëŠ” ì´ë¯¸ ì¡´ì¬í•¨)
        write_parquet(sas_data, parquet_file_path)
        
        # ë©”ëª¨ë¦¬ í•´ì œ
        rm(sas_data)
        gc(verbose = FALSE)
        
        # íŒŒì¼ í¬ê¸° ë¹„êµ
        parquet_size <- file.size(parquet_file_path) / 1024^2  # MBë¡œ ë³€ê²½
        size_saved <- original_size - parquet_size
        
        if (verbose) {
            cat(sprintf("    âœ“ ì™„ë£Œ: %.1f MB â†’ %.1f MB (%.1f%% ì ˆì•½)\n", 
                       original_size, parquet_size, (size_saved/original_size)*100))
        }
        
        return(list(
            success = TRUE,
            skipped = FALSE,
            original_size = original_size,
            parquet_size = parquet_size,
            size_saved = size_saved,
            compression_ratio = (size_saved/original_size)*100
        ))
        
    }, error = function(e) {
        return(list(
            success = FALSE,
            error = e$message
        ))
    })
}

# # outcome_tableì„ Parquetìœ¼ë¡œ ë³€í™˜
# convert_sas_to_parquet(paths$outcome_sas_file, paths$outcome_parquet_file, to_columns_lower = TRUE)

# # matched_date íŒŒì¼ë“¤ì„ ì¼ê´„ Parquet ë³€í™˜
# sas_files <- list.files(paths$matched_sas_folder, pattern = "\\.sas7bdat$", full.names = FALSE)

# for (matched_file in sas_files) {
#     sas_file_path <- file.path(paths$matched_sas_folder, matched_file)
#     parquet_file <- gsub("\\.sas7bdat$", "\\.parquet", matched_file)
#     parquet_file_path <- file.path(paths$matched_parquet_folder, parquet_file)
    
#     # ë²”ìš© ë³€í™˜ í•¨ìˆ˜ ì‚¬ìš©
#     convert_sas_to_parquet(sas_file_path, parquet_file_path, verbose = TRUE, to_columns_lower = TRUE)
# }

# ============================================================================
# ë°ì´í„° í™•ì¸: outcome_table.parquetê³¼ matched_date_parquet íŒŒì¼ ìƒìœ„ 10ê°œ row í™•ì¸
# ============================================================================

# # outcome_table.parquet íŒŒì¼ ìƒìœ„ 10ê°œ row í™•ì¸
# cat("\n=== outcome_table.parquet ìƒìœ„ 10ê°œ row ===\n")
# outcome_data <- read_parquet(parquet_outcome_file_path)
# print(head(outcome_data, 10))

# # matched_date_parquet í´ë”ì˜ ì²« ë²ˆì§¸ íŒŒì¼ ìƒìœ„ 10ê°œ row í™•ì¸
# matched_parquet_files <- list.files(parquet_matched_folder_path, pattern = "\\.parquet$", full.names = TRUE)
# if (length(matched_parquet_files) > 0) {
#     cat("\n=== matched_date_parquet í´ë” ì²« ë²ˆì§¸ íŒŒì¼ ìƒìœ„ 10ê°œ row ===\n")
#     cat(sprintf("íŒŒì¼ëª…: %s\n", basename(matched_parquet_files[1])))
#     matched_data <- read_parquet(matched_parquet_files[1])
#     print(head(matched_data, 10))
# } else {
#     cat("\nâŒ matched_date_parquet í´ë”ì— parquet íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n")
# }

# ============================================================================
# 2. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (Helper Functions) - HR/SHR ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
# ============================================================================

# HR ë¶„ì„ í•¨ìˆ˜ (ëª¨ë“ˆí™”)
perform_hr_analysis <- function(clean_data, fu, cause_abb, outcome_abb) {
    # Cox íšŒê·€ ë¶„ì„
    fit_coxph <- coxph(Surv(diff, status == 1) ~ case + strata(matched_id), data = clean_data)
    
    res_log_hr <- tidy(fit_coxph)
    res_hr <- tidy(fit_coxph, exponentiate = TRUE, conf.int = TRUE)
    
    # Cox íšŒê·€ ê²°ê³¼ ì •ë¦¬
    full_coxph_results <- res_log_hr %>%
        select(std.error, statistic, p.value, estimate) %>%
        rename(
            log_hr_values = estimate,
            hr_p_values = p.value,
            log_hr_std = std.error,
            log_hr_z_values = statistic
        ) %>%
        mutate(
            fu = fu,
            cause_abb = cause_abb,
            outcome_abb = outcome_abb,
            hr_values = res_hr$estimate,
            hr_lower_cis = res_hr$conf.low,
            hr_upper_cis = res_hr$conf.high
        ) %>%
        select(
            fu, cause_abb, outcome_abb, hr_values, hr_lower_cis, hr_upper_cis, 
            log_hr_values, hr_p_values, log_hr_std, log_hr_z_values
        )
    
    # ê²½ìŸìœ„í—˜ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
    clean_data_crr <- clean_data %>% mutate(
        status_factor = factor(
            status,
            levels = 0:2, 
            labels = c("censor", "outcome", "death")
        )
    )
    
    # ê²½ìŸìœ„í—˜ ë¶„ì„
    fit_crr <- crr(Surv(diff, status_factor) ~ case, data = clean_data_crr)
    
    res_log_shr <- tidy(fit_crr)
    res_shr <- tidy(fit_crr, exponentiate = TRUE, conf.int = TRUE)
    
    # ê²½ìŸìœ„í—˜ ë¶„ì„ ê²°ê³¼ ì •ë¦¬
    full_crr_results <- res_log_shr %>%
        select(std.error, statistic, p.value, estimate) %>%
        rename(
            log_shr_values = estimate,
            shr_p_values = p.value,
            log_shr_std = std.error,
            log_shr_z_values = statistic
        ) %>%
        mutate(
            shr_values = res_shr$estimate,
            shr_lower_cis = res_shr$conf.low,
            shr_upper_cis = res_shr$conf.high
        ) %>%
        select(
            shr_values, shr_lower_cis, shr_upper_cis, log_shr_values, 
            shr_p_values, log_shr_std, log_shr_z_values
        )
    
    # ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return(bind_cols(full_coxph_results, full_crr_results))
}

# ============================================================================
# 3ë‹¨ê³„: í•µì‹¬ ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“ˆ (Core Parallel Worker)
# ============================================================================

# ë‹¨ì¼ (Cause, Outcome) ìŒì„ ì²˜ë¦¬í•˜ëŠ”, ë³‘ë ¬ ì‘ì—…ì(worker)ê°€ ì‹¤í–‰í•  í•¨ìˆ˜
process_one_pair <- function(
    cause_abb, 
    outcome_abb, 
    fu, 
    matched_parquet_folder_path, 
    outcome_parquet_file_path, 
    results_hr_folder_path, 
    temp_slices_folder_path
    ) {
    
    # data.table ë‚´ë¶€ ìŠ¤ë ˆë”© ë¹„í™œì„±í™” (futureì™€ ì¶©ëŒ ë°©ì§€)
    setDTthreads(1)

    # 1. DuckDBë¡œ í•„ìš”í•œ ìµœì†Œ ë°ì´í„°ë§Œ ë””ìŠ¤í¬ì—ì„œ ì§ì ‘ ë¡œë“œ -> ì•„ì˜ˆ R ë©”ëª¨ë¦¬ ì œë¡œë¡œ ì§„í–‰
    con <- dbConnect(duckdb::duckdb())
    on.exit(dbDisconnect(con, shutdown = TRUE)) # í•¨ìˆ˜ ì¢…ë£Œ ì‹œ í•­ìƒ DB ì—°ê²° í•´ì œ
    
    # duckdb_register ì‚¬ìš©ì‹œ ë©”ëª¨ë¦¬ ì´ˆê³¼ ë°œìƒ
    # ë”°ë¼ì„œ, duckdbì—ì„œ ì§ì ‘ íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •

    # duckdb_register(
    #     con,
    #     "matched_pop_table",
    #     arrow::read_parquet(file.path(matched_parquet_folder_path, sprintf("matched_%s.parquet", tolower(cause_abb))))
    #  ) 

    matched_parquet_file_path <- file.path(matched_parquet_folder_path, sprintf("matched_%s.parquet", tolower(cause_abb)))
    
    # Outcomeì´ ë°œìƒí•œ ì‚¬ëŒê³¼ ê·¸ë ‡ì§€ ì•Šì€ ì‚¬ëŒì„ ëª¨ë‘ í¬í•¨í•˜ê¸° ìœ„í•´ LEFT JOIN ì‚¬ìš©
    query <- glue::glue("
        SELECT m.*, o.recu_fr_dt, o.abb_sick, o.key_seq AS outcome_key_seq
        FROM read_parquet('{matched_parquet_file_path}') AS m
        LEFT JOIN (
            SELECT person_id, recu_fr_dt, abb_sick, key_seq 
            FROM read_parquet('{outcome_parquet_file_path}') 
            WHERE abb_sick = '{outcome_abb}'
        ) AS o ON m.person_id = o.person_id
    ")
    
    clean_data <- as.data.table(dbGetQuery(con, query))

    # 2. ë°ì´í„° ì „ì²˜ë¦¬ (ì‹œê°„ ê³„ì‚° ë“±)
    clean_data[, `:=`(
        index_date = as.IDate(index_date, format = "%Y%m%d"),
        death_date = as.IDate(paste0(dth_ym, "15"), format = "%Y%m%d"),
        end_date = as.IDate(paste0(2003 + fu, "1231"), format = "%Y%m%d"),
        event_date = as.IDate(recu_fr_dt, format = "%Y%m%d")
    )]
    
    # final_date ë° status ê³„ì‚° (ì •í™•í•œ ë¡œì§ ì ìš©)
    clean_data[, final_date := fifelse(
        !is.na(event_date),
        pmin(event_date, end_date, na.rm = TRUE),
        pmin(death_date, end_date, na.rm = TRUE)
    )]
    clean_data[, status := fifelse(
        !is.na(event_date),
        fifelse(event_date <= final_date, 1, 0), 
        fifelse(!is.na(death_date) & death_date <= final_date, 2, 0)
    )]
    
    clean_data[, diff := final_date - index_date]
    
    # diff < 0 ì¸ matched_id ê·¸ë£¹ ì „ì²´ ì œê±°
    problem_ids <- clean_data[diff < 0, unique(matched_id)]
    if (length(problem_ids) > 0) {
        clean_data <- clean_data[!matched_id %in% problem_ids]
    }
    
    # 3. HR ë¶„ì„ ìˆ˜í–‰ ë° ìµœì¢… ê²°ê³¼ ì €ì¥ (Scatter)
    hr_result <- perform_hr_analysis(clean_data, fu, cause_abb, outcome_abb)
    filename_hr <- sprintf("hr_%s_%s_%d.parquet", cause_abb, outcome_abb, fu)
    write_parquet(hr_result, file.path(results_hr_folder_path, filename_hr))

    # 4. Edge ë§¤í•‘ ë°ì´í„° ì¡°ê° ìƒì„± ë° ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (Scatter)
    key <- paste(cause_abb, outcome_abb, fu, sep = "_")
    
    # diff < 0 ì œê±° í›„ ë‚¨ì€ 'case' ê·¸ë£¹ì— ëŒ€í•´ì„œë§Œ ì •ë³´ ìˆ˜ì§‘
    edge_slice <- list(
        pids = clean_data[case == 1, .(person_id)],
        index_key_seq = clean_data[case == 1, .(index_key_seq)],
        key_seq = clean_data[case == 1 & status == 1, .(outcome_key_seq)]
    )
    
    # ê³ ìœ í•œ ì„ì‹œ íŒŒì¼ ì´ë¦„ ìƒì„± ë° ì €ì¥
    slice_filename <- sprintf("edge_slice_%s.rds", digest::digest(key))
    saveRDS(list(key = key, data = edge_slice), file.path(temp_slices_folder_path, slice_filename))
    
    return(TRUE)
}

# ============================================================================
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (Main Executor)
# ============================================================================

run_hr_analysis <- function(
    cause_list, 
    outcome_list, 
    fu, 
    n_cores,
    matched_parquet_folder_path, 
    outcome_parquet_file_path, 
    results_hr_folder_path, 
    temp_slices_folder_path
    ) {
    cat("\n--- [ë‹¨ê³„ 1] í•µì‹¬ ë³‘ë ¬ ë¶„ì„ ì‹œì‘ ---\n")
    
    # --- ì‘ì—… ëª©ë¡ ìƒì„± ---
    instruction_list <- tidyr::expand_grid(cause_abb = cause_list, outcome_abb = outcome_list) %>%
        filter(cause_abb != outcome_abb)
    cat(sprintf("ì´ %dê°œ ì¡°í•© ë¶„ì„ ì‹œì‘ (Core: %d)\n", nrow(instruction_list), n_cores))
    
    # --- ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì • ë° ì‹¤í–‰ ---
    plan(multisession, workers = n_cores)
    required_packages <- c("data.table", "duckdb", "arrow", "survival", "broom", "tidycmprsk", "dplyr", "glue", "digest")
    
    progressr::with_progress({
        p <- progressr::progressor(steps = nrow(instruction_list))
        
        future_walk(1:nrow(instruction_list), function(i) {
            current_cause <- instruction_list$cause_abb[i]
            current_outcome <- instruction_list$outcome_abb[i]
            
            tryCatch({
                process_one_pair(
                    current_cause, current_outcome, fu,
                    matched_parquet_folder_path,
                    outcome_parquet_file_path,
                    results_hr_folder_path,
                    temp_slices_folder_path
                )
            }, error = function(e) {
                cat(sprintf("\nERROR in %s -> %s: %s\n", current_cause, current_outcome, e$message))
            })
            p()
        }, .options = furrr_options(seed = TRUE, packages = required_packages))
    })
    
    plan(sequential)
    cat("\n--- [ë‹¨ê³„ 1] í•µì‹¬ ë³‘ë ¬ ë¶„ì„ ì™„ë£Œ ---\n")
}

# ============================================================================
# 5. ë°ì´í„° ì·¨í•© í•¨ìˆ˜ (Data Aggregator)
# ============================================================================

aggregate_mappings <- function(
    cause_list,
    fu, 
    matched_parquet_folder_path, 
    results_mapping_folder_path,
    temp_slices_folder_path
    ) {
    cat("\n--- [ë‹¨ê³„ 2] ìµœì¢… ë§¤í•‘ ë°ì´í„° ì·¨í•© ì‹œì‘ ---\n")
    # --- Node ë§¤í•‘ ë°ì´í„° ìƒì„± ---
    cat("1. Node ë§¤í•‘ ë°ì´í„° ìƒì„± ì¤‘...\n")
    node_pids_list <- list()
    node_index_key_seq_list <- list()
    
    for (cause_abb in cause_list) {
        key <- paste(cause_abb, fu, sep = "_")
        matched_path <- file.path(matched_parquet_folder_path, sprintf("matched_%s.parquet", tolower(cause_abb)))
        if (file.exists(matched_path)) {
            matched_data <- read_parquet(matched_path, col_select = c("person_id", "index_key_seq", "case"))
            node_pids_list[[key]] <- matched_data$person_id
            node_index_key_seq_list[[key]] <- matched_data$index_key_seq[matched_data$case == 1]
        }
    }
    save_mapping_to_parquet(node_pids_list, "node_pids", results_mapping_folder_path, fu)
    save_mapping_to_parquet(node_index_key_seq_list, "node_index_key_seq", results_mapping_folder_path, fu)
    rm(node_pids_list, node_index_key_seq_list); gc()

    # --- Edge ë§¤í•‘ ë°ì´í„° ì·¨í•© ---
    cat("\n2. Edge ë§¤í•‘ ë°ì´í„° ì·¨í•© ì¤‘...\n")
    edge_pids_list <- list()
    edge_index_key_seq_list <- list()
    edge_key_seq_list <- list()
    
    slice_files <- list.files(temp_slices_folder_path, full.names = TRUE, pattern = "\\.rds$")
    cat(sprintf("%dê°œì˜ Edge ë°ì´í„° ì¡°ê°ì„ ì·¨í•©í•©ë‹ˆë‹¤.\n", length(slice_files)))
    
    if (length(slice_files) > 0) {
        progressr::with_progress({
            p <- progressr::progressor(steps = length(slice_files))
            for (slice_file in slice_files) {
                slice <- readRDS(slice_file)
                key <- slice$key
                edge_pids_list[[key]] <- unlist(slice$data$pids, use.names = FALSE)
                edge_index_key_seq_list[[key]] <- unlist(slice$data$index_key_seq, use.names = FALSE)
                edge_key_seq_list[[key]] <- unlist(slice$data$key_seq, use.names = FALSE)
                p()
            }
        })
    }
    
    save_mapping_to_parquet(edge_pids_list, "edge_pids", results_mapping_folder_path, fu)
    save_mapping_to_parquet(edge_index_key_seq_list, "edge_index_key_seq", results_mapping_folder_path, fu)
    save_mapping_to_parquet(edge_key_seq_list, "edge_key_seq", results_mapping_folder_path, fu)
    rm(edge_pids_list, edge_index_key_seq_list, edge_key_seq_list); gc()
    
    cat("--- [ë‹¨ê³„ 2] ìµœì¢… ë§¤í•‘ ë°ì´í„° ì·¨í•© ì™„ë£Œ ---\n")
}

# R ë¦¬ìŠ¤íŠ¸ë¥¼ Parquetìœ¼ë¡œ ì €ì¥í•˜ëŠ” ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í—¬í¼ í•¨ìˆ˜
save_mapping_to_parquet <- function(mapping_list, type, output_dir, fu) {
    if (length(mapping_list) == 0) {
        cat(sprintf("   - '%s' ë§¤í•‘ ë°ì´í„°ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.\n", type))
        return()
    }
    
    cat(sprintf("   - '%s' ë§¤í•‘ ì €ì¥ ì¤‘...\n", type))
    
    # ë¦¬ìŠ¤íŠ¸ë¥¼ key-value ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    df <- data.frame(
        key = names(mapping_list),
        stringsAsFactors = FALSE
    )
    df$values <- I(mapping_list) # ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©° ì»¬ëŸ¼ì— ì‚½ì…
    
    # Parquet íŒŒì¼ë¡œ ì €ì¥
    parquet_file <- file.path(output_dir, sprintf("%s_mapping_%d.parquet", type, fu))
    arrow::write_parquet(df, parquet_file)
    
    cat(sprintf("     âœ“ ì™„ë£Œ: %s\n", basename(parquet_file)))
}

# ============================================================================
# 6. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (Script Execution)
# ============================================================================

# ì§ˆë³‘ ì½”ë“œ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
get_disease_codes_from_path <- function(matched_parquet_folder_path) {
    codes <- toupper(gsub("matched_(.*)\\.parquet", "\\1", list.files(matched_parquet_folder_path)))
    return(sort(codes))
}

paths <- list(
        matched_sas_folder = "/home/hashjamm/project_data/disease_network/sas_files/hr_project/matched_date/",
        matched_parquet_folder = "/home/hashjamm/project_data/disease_network/matched_date_parquet/",
        outcome_sas_file = "/home/hashjamm/project_data/disease_network/sas_files/hr_project/hr_std_pop10.sas7bdat",
        outcome_parquet_file = "/home/hashjamm/project_data/disease_network/outcome_table.parquet",
        results_hr_folder = "/home/hashjamm/results/disease_network/hr_results_final/",
        results_mapping_folder = "/home/hashjamm/results/disease_network/hr_mapping_results_final/",
        temp_slices_folder = file.path(tempdir(), "edge_slices")
    )

handlers(handler_progress(format = "[:bar] :current/:total (:percent) | ETA: :eta"))

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
main <- function(paths = paths, fu, n_cores = 90) {
    
    total_start_time <- Sys.time()
    
    # --- ì‹¤í–‰ ìˆœì„œ ---
    
    # 1. ì „ì²´ ì§ˆë³‘ ì½”ë“œ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    disease_codes <- get_disease_codes_from_path(file.path(paths$matched_parquet_folder))
    
    # 2. í•µì‹¬ ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
    run_hr_analysis(
        disease_codes, disease_codes, fu, n_cores,
        matched_parquet_folder_path = paths$matched_parquet_folder,
        outcome_parquet_file_path = paths$outcome_parquet_file,
        results_hr_folder_path = paths$results_hr_folder,
        temp_slices_folder_path = paths$temp_slices_folder
    )
    
    # 3. ìµœì¢… ë°ì´í„° ì·¨í•©
    aggregate_mappings(
        disease_codes, fu,
        matched_parquet_folder_path = paths$matched_parquet_folder,
        results_mapping_folder_path = paths$results_mapping_folder,
        temp_slices_folder_path = paths$temp_slices_folder
    )
    
    # --- ìµœì¢… ìš”ì•½ ---
    total_elapsed <- as.numeric(difftime(Sys.time(), total_start_time, units = "hours"))
    cat(sprintf("\nëª¨ë“  ì‘ì—… ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: %.2fì‹œê°„ (%.1fì¼)\n", total_elapsed, total_elapsed/24))
    cat(sprintf("HR ê²°ê³¼ë¬¼ ìœ„ì¹˜: %s\n", paths$results_hr_folder))
    cat(sprintf("ë§¤í•‘ ê²°ê³¼ë¬¼ ìœ„ì¹˜: %s\n", paths$results_mapping_folder))
}

main(paths = paths, fu = 10, n_cores = 30)
